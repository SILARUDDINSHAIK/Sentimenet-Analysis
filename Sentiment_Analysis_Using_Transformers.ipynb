{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "KvOezcRFTEWp",
    "outputId": "d5e21cdd-8f63-41ac-c41b-d11bb90903b1"
   },
   "outputs": [],
   "source": [
    "import transformers \n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('Yelptrain.csv')\n",
    "df_train[\"label\"].replace({1: 0, 2: 1}, inplace=True)\n",
    "class_name = ['negative','positive']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_flJvE2tHJAH"
   },
   "source": [
    "#### Setting device as per the availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sOVZXQIqhvcj",
    "outputId": "0b50e1e1-feb2-4640-d24a-3420fa22f79f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-iFmMbGyUKYC"
   },
   "outputs": [],
   "source": [
    "# Pretrained Model \n",
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uTQFtWm4UL2d"
   },
   "outputs": [],
   "source": [
    "#Load Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b2v_MX4pHRNb"
   },
   "source": [
    "#### Loading pre-trained bert tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "s0E5cHLSh6FR",
    "outputId": "18fbc663-5b4c-4098-c28c-088e0a9136d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 1000/1000 [00:02<00:00, 486.92it/s]\n",
      "/Users/silaruddin/ENTER/lib/python3.8/site-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD4CAYAAAD7CAEUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAuMElEQVR4nO3deXxU9b3/8dcny2TfFwIJIQmEfQdZBK3iBi7g2uK+Vm3VW2t/bbX2ertcr9f2urS92tbdq1JBrJarXBUEFUUT9p1AQkJCWLLve+b7+2MONsZAEsjkzEw+z8djHp45c86Z95A4n3zP95zvV4wxKKWUUj3lZ3cApZRS3kULh1JKqV7RwqGUUqpXtHAopZTqFS0cSimleiXA7gD9IT4+3qSlpdkdQymlvMamTZvKjDEJXb02IApHWloaGzdutDuGUkp5DRE5eKLX9FSVUkqpXtHCoZRSqle0cCillOoVLRxKKaV6RQuHUkqpXtHCoZRSqle0cCillOoVLRxKKaV6RQuHUkqpXhkQd46r7i3JKjyl/a6bmdrHSZRSnk5bHEoppXpFC4dSSqle0cKhlFKqV7RwKKWU6hUtHEoppXpFC4dSSqle0cKhlFKqV7RwKKWU6hUtHEoppXpFC4dSSqle0cKhlFKqV7RwKKWU6hUtHEoppXpFC4dSSqlecWvhEJH5IpIjIrki8mAXrweJyFLr9SwRSevw2kPW+hwRuajTfv4iskVE3nNnfqWUUt/mtsIhIv7AM8ACYCxwrYiM7bTZ7UClMWYE8BTwuLXvWGAxMA6YDzxrHe+4HwF73JVdKaXUibmzxTEDyDXGHDDGtABvAos6bbMIeNVaXg6cJyJirX/TGNNsjMkHcq3jISIpwCXAC27MrpRS6gTcOQNgMlDU4fkhYOaJtjHGtIlINRBnrf+q077J1vLTwM+AiJO9uYjcCdwJkJqqs9S5y6nOHAg6e6BS3sqrOsdF5FKgxBizqbttjTHPGWOmG2OmJyQk9EM6pZQaGNxZOIqBoR2ep1jrutxGRAKAKKD8JPvOARaKSAGuU1/zROR1d4RXSinVNXcWjg1Apoiki4gDV2f3ik7brAButpavBtYYY4y1frF11VU6kAlkG2MeMsakGGPSrOOtMcbc4MbPoJRSqhO39XFYfRb3Ah8C/sBLxphdIvIbYKMxZgXwIvCaiOQCFbiKAdZ2y4DdQBtwjzGm3V1ZlVJK9Zw7O8cxxqwEVnZa90iH5SbgmhPs+yjw6EmO/QnwSV/kVKcvt6SO7IIKCsrqaWptJybUQUZCGGcOjychIsjueEqpPuTWwqF8X3NrOyu2HWZLURWhDn9GJ0US6vCnrK6ZzYWVZOdXMCM9losnDCbQ36uuxVBKnYAWDnXKmtvaeemLfA5VNjJvdCLnjEogwO+fxaGuuY21OSV8mVdOflk9N5+ZRkyow8bESqm+oH8CqlPS7jS8/tVBiqsauW5mKuePGfSNogEQHhTAZROHcOuZadQ0tfLXT/MoqWmyKbFSqq9o4VCn5JOcEvJK67liSgrjhkSddNvMQRF8/6wMnAZe+iKfyoaWfkqplHIHLRyq14oqGlibU8KUodFMGxbTo30GR4Vw29x0WtqdvPJFAY0tepGcUt5KC4fqFacx/GNbMRHBgVw2aUiv9k2KDObGWWlU1LewbGMRTqdxU0qllDtp4VC9sv1QNYermrhw7CCCA/2736GT9PgwLpk4mJxjtfxpTa4bEiql3E0Lh+qxtnYnq3YfZUhUMJOGRp/ycWamxzJ5aDR/XLOfrUVVfZZPKdU/tHCoHtt2qIrKhlYuHJeEn8gpH0dEuGziEBIjgvjJsq00tWp/h1LeRAuH6hFjDOv2lzE4KpjMxPDTPl6Iw5/fXz2JvNJ6fvdBTh8kVEr1F70BUPXI/pI6SmqbuWZaCnIarY2OCisamJkey0tf5OMnkJHQs4Kk83goZS9tcageWZ9XRmRwABNSTn7PRm8tGD+YuDAHf99STGu7s0+PrZRyDy0cqltVDS3sP1bHtGGx37o7/HQ5AvxYNDmZivoW1u0v7dNjK6XcQwuH6tbmwioM9Phmv94akRjO+OQoPskppaJe7ypXytNp4VAn5TSGzYWVZCSEERvmvgEKLx6fhAi8v+OI295DKdU3tHCokyosb6CivoVpqe5pbRwXHepg3uhB7DlSQ87RWre+l1Lq9GjhUCe1o7iaAD9h7JBIt7/XnBFxxIcH8d72w7TrcCRKeSwtHOqEnMaw83A1o5IiCAro/fAivRXg58fFE5Ior28hO7/c7e+nlDo1WjjUCR0sb6C2qY0JyX17Ce7JjBoUQUZ8GB/vLdE7ypXyUFo41AntKK4iwE8YlRTRb+8pIiwYP5iGlnY+26eX5yrlibRwqC4ZY9hzpJaRg/rnNFVHyTEhTEqJ4vPcMqobW/v1vZVS3dPCobp0tKaJ6sZWRvdja6OjC8cmYYBVu4/Z8v5KqRPTwqG6tNe6JLY/T1N1FBPmYHZGHFsKK3WecqU8jBYO1aW9R2pIiQkhIjjQtgxnj0wgMMCPj/eW2JZBKfVtWjjUt9Q1t3GostG201THhQcFcObwOHYUV3OkutHWLEqpf9LCob5l/7FaDDAqyf03/XXnrBEJBAf6sXqPtjqU8hRaONS35JbUEebwZ3BUsN1RCHH4M3dEAnuO1HCossHuOEoptHCoTowx5JbWMTwx/LSmh+1Lc4bHEerwZ/UevcJKKU+ghUN9w7HaZmqb2hjRw9n4+kNQoD9nZyaw71gdBWX1dsdRasDTwqG+IbekDnDNkeFJZmXEER4UwCptdShlOy0c6htyS2qJDw8iOtR9c2+cCkeAH+eMSiC/rJ4vcsvsjqPUgKaFQ33NaQwHyxvISAizO0qXzkiLJSokkKdX78MYHXZdKbto4VBfO1LdRHObk/Q4zywcgf5+fGdkAhsKKlmfp8OuK2UXLRzqa8c7ntPiPbNwAEwfFkNSZLC2OpSykRYO9bWC8npiQgOJCrFvmJHuBPj7cc+5w7XVoZSNtHAowHX/RkFZPWkeepqqo++eMVRbHUrZSAuHAqC0rpn6lnbSPfg01XFBAf7a6lDKRlo4FAAFZa7hPLyhxQHa6lDKTm4tHCIyX0RyRCRXRB7s4vUgEVlqvZ4lImkdXnvIWp8jIhdZ64JFJFtEtonILhH5tTvzDyQF5fWEBwUQF+5Z92+ciLY6lLKP2wqHiPgDzwALgLHAtSIyttNmtwOVxpgRwFPA49a+Y4HFwDhgPvCsdbxmYJ4xZhIwGZgvIrPc9RkGElf/RijiIeNT9YS2OpSyhztbHDOAXGPMAWNMC/AmsKjTNouAV63l5cB54vrmWgS8aYxpNsbkA7nADONSZ20faD30G+M0HapsoKqx1aMvw+2KtjqUsoc7C0cyUNTh+SFrXZfbGGPagGog7mT7ioi/iGwFSoBVxpisrt5cRO4UkY0isrG0tPT0P40P21BQAXhP/0ZH2upQqv95Xee4MabdGDMZSAFmiMj4E2z3nDFmujFmekJCQr9m9DbZ+ZUEBfiR5AHzb/SWtjqU6n/uLBzFwNAOz1OsdV1uIyIBQBRQ3pN9jTFVwFpcfSDqNGwoqGBYXKjHzL/RW9rqUKp/ubNwbAAyRSRdRBy4OrtXdNpmBXCztXw1sMa4/s9fASy2rrpKBzKBbBFJEJFoABEJAS4A9rrxM/i8mqZW8krrSI0NtTvKKQsK8OeH2upQqt+4rXBYfRb3Ah8Ce4BlxphdIvIbEVlobfYiECciucADwIPWvruAZcBu4APgHmNMOzAYWCsi23EVplXGmPfc9RkGgu1F1RgDQ2O8t3AAfHe6tjqU6i8B7jy4MWYlsLLTukc6LDcB15xg30eBRzut2w5M6fukA9fWokoAUry8cAQHulodj/xjF+vzypkzIt7uSEr5LK/rHFd9a2tRFRkJYYQ4/O2Octq01aFU/9DCMYAZY9haVMXkodF2R+kTx1sd2tehlHtp4RjAiqsaKatrYYqPFA7QVodS/UELxwC2tagKgEk+VDi01aGU+2nhGMC2FlbhCPBjdFKk3VH6lLY6lHIvLRwD2NaiKsYPicQR4Fu/BtrqUMq9fOsbQ/VYa7uTHcXVTB4aY3cUt9BWh1Luo4VjgMo5Wktzm5PJqdF2R3ELbXUo5T5uvQFQea7jHePeeEXVkqzCHm1nDEQGB/DQ33dw19kZiAjXzUx1czqlfJ+2OAaorUVVxIU5SIkJsTuK2wT6+zFv9CAKKxrYe7TW7jhK+QwtHAPU8Rv/vGnGv1MxbVgM8eEOPtx1FKf2dSjVJ3pUOETk7yJyiYhoofEBdc1t5JXWMSElyu4obufvJ1w4NomS2ma2FFbaHUcpn9DTQvAscB2wX0T+U0RGuTGTcrPdh2swBiYk+37hABg3JJKUmBBW7ymhqbXd7jhKeb0eFQ5jzGpjzPXAVKAAWC0i60XkVhEJdGdA1fd2FFcDA6dwiAjzxyVR3djKq+sL7I6jlNfr8aknEYkDbgHuALYAf8BVSFa5JZlym13F1SRGBJEY6X1TxZ6qjIRwRg4K55m1uVTUt9gdRymv1tM+jneAdUAocJkxZqExZqkx5j4g3J0BVd/bUVw9YFobHS0YP5j6lnaeWrXP7ihKebWetjieN8aMNcY8Zow5AiAiQQDGmOluS6f6XEOLq2N8/AAsHIMig7lhZipvZB0kRy/PVeqU9bRw/HsX677syyCqf+w+XIPTMCALB8D9548kIjiQ3763W4ciUeoUnbRwiEiSiEwDQkRkiohMtR7n4DptpbzMQOsY7ywmzMGPz8/k89wyPt5TYnccpbxSd0OOXISrQzwFeLLD+lrgF27KpNxoR3E18eFBDIoMsjuKba6fNYzXswr57fu7mZsZT3Cg90+bq1R/OmmLwxjzqjHmXOAWY8y5HR4LjTF/76eMqg/tKq5hQnKkz98xfjKB/n78ZuE4DpY38OzaXLvjKOV1TtriEJEbjDGvA2ki8kDn140xT3axm/JQjS3t7C+p5aJxg+yOYrszR8RzxZRk/vxpHgsnJzMiUS8OVKqnuuscD7P+Gw5EdPFQXmT3kYHdMd7Zw5eMISTQn4ff2aEd5Ur1wklbHMaYv1r//XX/xFHutNPqGNfC4RIfHsSDC8bwi3d28PbmYq6elmJ3JKW8Qk9vAPydiESKSKCIfCwipSJyg7vDqb61o7iauDAHg6MGzh3j3Vl8xlCmDYvh0fd3U1LbZHccpbxCTydyutAY8zMRuQLXWFVXAp8Br7srmOq97iY4+nx/GXHhDv6WXdRPiTxPV/9GZ2XGs62oiptezObGWcO6vHBAJ4BS6p96egPg8QJzCfCWMabaTXmUm7S2OympbWJItO9O3HSqEiOCuWhcEnuP1rJZh15Xqls9LRzvicheYBrwsYgkANqu9yJHq5twGkjWwtGl2cPjSI8P473tR6hs0EEQlTqZng6r/iBwJjDdGNMK1AOL3BlM9a3iqkZAC8eJ+Ilw1dQUDLB80yGdLVCpk+jNjH6jge+JyE3A1cCF7omk3KG4qpFQhz9RITp9yonEhjm4bOJg8svqWbNXhyNR6kR61DkuIq8Bw4GtwPEp1AzwP+6Jpfra4apGkqNDBvQd4z0xNTWG/LJ61u4tYVhsKJmD9HYlpTrr6VVV04GxRu+S8kqt7U6O1TQxMjPB7igeT0RYOCmZQ5WNLN1YxH3zMrWVplQnPT1VtRNIcmcQ5T7HarRjvDccAX5cNzOVNqfhb9mFtLU77Y6klEfpaeGIB3aLyIcisuL4w53BVN/RjvHeS4wI5sopyRRWNPDu1mIdkkSpDnp6qupX7gyh3Ku4spGQQH+iQ/WUS29MTImmtK6Zj/eU8MzaXO6dl2l3JKU8Qo8KhzHmUxEZBmQaY1aLSCigkxh4Ce0YP3XzRiVSXtfCf320j2FxYVw2aYjdkZSyXU/Hqvo+sBz4q7UqGXjXTZlUH2prd3KsplnvGD9FIsKVU5I5Iy2Gn7y1jfW5ZXZHUsp2Pe3juAeYA9QAGGP2A4nuCqX6ztGaJtqNITlGC8epCvD347kbp5MeF8Yd/7ORTQd1WBI1sPW0cDQbY74eh0FEAnDdx3FSIjJfRHJEJFdEHuzi9SARWWq9niUiaR1ee8hanyMiF1nrhorIWhHZLSK7RORHPcw/YB2uco0Mox3jpycmzMFrd8wgMSKIW17O/nqIeqUGop4Wjk9F5BdAiIhcALwF/O/JdhARf+AZYAEwFrhWRMZ22ux2oNIYMwJ4Cnjc2ncssBgYB8wHnrWO1wb8xBgzFpgF3NPFMVUHxVWNBAf6EaMd46ctMSKYN74/i8jgQG58MUuLhxqwelo4HgRKgR3AXcBK4Jfd7DMDyDXGHLBaK2/y7fGtFgGvWsvLgfPE1YO7CHjTGNNsjMkHcoEZxpgjxpjNAMaYWmAPrv4WdQKHqxoZoh3jfSY5OoQ37phJSKA/1z7/FZsOVtgdSal+19NBDp24OsN/aIy52hjzfA/uIk8GOk78cIhvf8l/vY0xpg2oBuJ6sq91WmsKkNXVm4vInSKyUUQ2lpaWdhPVN7U5nRytadLTVH0sLT6Mt35wJvHhQdzwQjbr9g/M3y81cJ20cIjLr0SkDMgBcqzZ/x7pn3gnzBUOvA3cb4yp6WobY8xzxpjpxpjpCQkDc6iNYzXNtDuNFg43SI4OYdldsxkWF8rtr2zkg51H7Y6kVL/prsXxY1xXU51hjIk1xsQCM4E5IvLjbvYtBoZ2eJ5iretyG6vDPQooP9m+IhKIq2i8YYz5ezcZBrTiSr1j3J0SIoJYeudsxiVHcs+Szby96ZDdkZTqF90VjhuBa61+BgCMMQeAG4Cbutl3A5ApIuki4sDV2d15mJIVwM3W8tXAGusU2ApgsXXVVTqQCWRb/R8vAnuMMU92//EGtuKqBoID/YgNc9gdxWdFhQby+u0zmZURy0/e2sbznx2wO5JSbtdd4Qg0xnzrjidjTClw0st0rD6Le4EPcXViLzPG7BKR34jIQmuzF4E4EckFHsDVCY8xZhewDNgNfADcY4xpx9X6uRGYJyJbrcfFPfysA05xVSMp0aHaMe5mYUEBvHTLGVwyYTCPrtzDf6zcg9OpY1sp39XdkCMnm0Oz2/k1jTErcV2B1XHdIx2Wm4BrTrDvo8CjndZ9Dui3YA+0tTs5Vt3MnBE6n0R/CArw54/XTiEu3MFznx2grK6Zx6+aSKB/b+ZKU8o7dFc4JolIV53PAgS7IY/qI3rHeP/z9xN+vXAcCeFBPLFqH5X1LTxz/VTe3XL4lI533czUPk6oVN84aeEwxuhAhl7q+FDqKdox3q9EhPvOyyQ+IoiH39nB9S9kccn4wYQG9XQgaqU8n/42+ygdSt1e185IJTbMwX1/28KhikZunZNGdKhepKB8gxYOH1Vc1UhKjN4xbqeLxiXx2m0zuPnlbP7yaR63zUknMVLP8HqCJVmFp7Sfnj500Z47H3R8jnG9f8N+MzPiuPOs4RgDL3yez7GaJrsjKXXatHD4oKPVrjnGdQ4Oz5AUFcztZ6UjaPFQvkELhw/6umNcr6jyGIkRwdxxVgZ+Ai+sO6DFQ3k17ePwQcWVjYQ6/IkK0Y7xvnKq58Q7SogI4vtzM3j+8wO8/EU+d509nBi9q195IW1x+CDtGPdc8RFB3HpmOi3tTl76Ip/apla7IynVa1o4fExLm5OSWu0Y92RJUcHcMjuNmqZWXllfQGNLu92RlOoVLRw+5mh1I06jI+J6utS4MK6fOYySmmaWZB+kXce2Ul5EC4ePOd4xnhwTanMS1Z2RgyK4YkoyeaX1/GNrMd3PjaaUZ9DOcR9TXNVIeFAAkcH6o/UGU4fFUFbfzCc5pcSHB3H2yIE56ZjyLvrt4mMOVTaSrHOMe5XzxwyivK6FD3cdJT7cwdghUXZHUuqk9FSVD2lpc1Ja26wj4noZPxGunpZCckwIyzYdokTv8VAeTguHDzlS3YhBO8a9UaC/H9fPHEagn/B6ViFNrXqllfJcWjh8yCGdY9yrRYUEcu3MVCrqm1m+6ZDOIqg8lhYOH1Jc1UhEcACRese418qID2fB+MHsPlLDnz/NszuOUl3SwuFDiioaGKqX4Xq9M4fHMSkliv/6KIdPckrsjqPUt2jh8BEV9S2U17eQGquFw9uJCFdMSWHUoAh+9OZWiioa7I6k1Ddo4fARW4sqARiqhcMnOAL8eO7G6RhjuPv1TdpZrjyKFg4fsaWwCj/RjnFfkhoXylPfm8yuwzX82z922R1Hqa9p4fARWwqrSIoMxhGgP1Jfct6YQdx77giWbixi6YbTH9pdqb6g3zI+oN1p2FpUpaepfNSPLxjJ3BHx/Os/drGzuNruOEpp4fAFuSV11DW3aeHwUf5+wh8WTyYuzMHdr2+iqqHF7khqgNPC4QO2FLo6xlP1UlyfFRcexLPXT+VYTRMPLNumNwcqW2nh8AFbCquIDg0kLlynIfVlU1JjeOTSsazZW8Iza3PtjqMGMC0cPmBLUSVThkbriLgDwA2zhnH55CE8uXof6/aX2h1HDVA6rLqXq2lqZX9JHZdOHGJ3FNXHlmR1fRXV5KExfHmgnLte28S9544gOvTbLc3rZqa6O54awLTF4eW2F1VjDExJjbY7iuonjgA/rp8xjHan4Y2sQlranHZHUgOMFg4vt6WwEhGYNDTa7iiqH8VHBPHd6UM5XNXI8s2HcOq0s6ofaeHwcpsKKxmREE5ksI6IO9CMGRzJ/PFJ7CyuZs1eHQxR9R8tHF6srd3JxoJKZqTH2h1F2WTuiHimDYthzd4SthZV2R1HDRDaOe7Fdh+poa65jZkZcXZHUTYRERZNHkJFfQtvbz5EeFAAIxLD7Y6lfJy2OLxYdn4FADO1xTGgBfj5ccPMYSSEB/H6Vwd1GHbldlo4vNhXBypIiwtlUGSw3VGUzUIc/twyJ43w4ABeWV9Abkmt3ZGUD9PC4aWcTsOGggrt31BfiwwO5LY56QT4Cdc9n6XFQ7mNFg4vlXOslurGVmama/+G+qfYMAe3zU3HaeC7f/2KXYd1NF3V99xaOERkvojkiEiuiDzYxetBIrLUej1LRNI6vPaQtT5HRC7qsP4lESkRkZ3uzO7psg6UAzAzQ1sc6psGRQbz1t2zCQ7w49rnvmKzNQimUn3FbYVDRPyBZ4AFwFjgWhEZ22mz24FKY8wI4CngcWvfscBiYBwwH3jWOh7AK9a6AS27oILk6BBSdERc1YX0+DCW3T2bmDAH1z+fxQc7j9gdSfkQd7Y4ZgC5xpgDxpgW4E1gUadtFgGvWsvLgfPENVLfIuBNY0yzMSYfyLWOhzHmM6DCjbk9njGG7PwKvZpKnVRKTChv3T2bUUkR3P36Zv6wej9G7zBXfcCdhSMZKOrw/JC1rsttjDFtQDUQ18N9B6y80nrK6lq0Y1x1KzEimDfvnMWVU5N5avU+fvjGZqobW+2Opbycz3aOi8idIrJRRDaWlvrW8NNZ+cf7N7RjXHUvONCfJ66ZxMMXj+Gj3cdY8PRnrM8rszuW8mLuLBzFwNAOz1OsdV1uIyIBQBRQ3sN9T8oY85wxZroxZnpCQkIvo3u2rAMVJEYEkRan/RuqZ0SE75+dwds/OJOgQH+ufyGLf39vNw0tbXZHU17InYVjA5ApIuki4sDV2b2i0zYrgJut5auBNcZ1EnYFsNi66iodyASy3ZjVazidhvV5ZcweHqcTN6lemzw0mvf/ZS7XzUjlhc/zOe+JT3l/+xHt+1C94rbCYfVZ3At8COwBlhljdonIb0RkobXZi0CciOQCDwAPWvvuApYBu4EPgHuMMe0AIvI34EtglIgcEpHb3fUZPNHeo7WU1bVwVqZvtaJU/wl1BPDoFRNYfvdsYkId3LNkM9c9n6WDJKoec+sgh8aYlcDKTuse6bDcBFxzgn0fBR7tYv21fRzTqxyfLnTuiHibkyhvNz0tlv+9by5Lsgt58qMcLn/mC8YkRXD+2EEMjgrp9fF01sGBw2c7x33Vuv1ljBwUTlKUjk+lTp+/n3DjrGGs+/k8fnLBSPLL6/nTmlxeXV9AXmmdnsJSXdJh1b1IU2s72QUV3DhrmN1RlI8JDwrgvvMyCXUE8OWBMr7MK+fFz/NJjg5hbmY844dE4e+nfWrKRQuHF/nqQDktbU7mZuppKuUeIQ5/5o0exFmZCWwtrGJdbhlLNxTxYehR5gyPZ/qwGIIC/bs/kPJpWji8yNq9JQQH+jFb799Q3ViSVXha+wf6+3FGeizT0mLIOVrLuv1lvL/jCB/vPcbM9DhmZ8QRGeK70xWX1zVzqKqRmsZW/P2EyOBA0uPD7I7lMbRweAljDGtySpgzPJ5g/YtP9RM/EcYMjmTM4EiKKhpYl1vGZ/tK+Xx/GZOGRjM3M54kH5kPpqm1nY0FFWQXVFBW19LlNp/nlvGDc4Yza4D/8aaFw0vkltRRVNHI3d8ZbncUNUANjQ3luhmpVNS38EVuGRsPVrC5sJKRg8I5Z2Si3fFOWbvTkJ1fzsd7S2hoaWdYbCizJ8aRFh9GTKiDdqehvK6ZfSV1bD9UzeLnvuLKKck8ctlYokMddse3hRYOL/Hx3hIAzh3lvf+DKt8QG+bgsklDOG9MIln5FazPK+e5dQfYfaSG+8/PZHqa94yhdqS6kb9vLqa4qpGMhDDmj0vqcsTpsKAAUuPCePb6qTz7SR7Prs1l48FKXrplOiMSI2xIbi+9HNdLrNlTwuikCIZE9/76eqXcIdQRwLmjEvnphaO4eHwSe4/WcPVfvuTGF7PYdNCz5wAxxvDVgXL+/EkeVY2tLD5jKLfPSe92moLgQH8euGAky+6eTUNLO1c8u35AzneihcMLlNQ2seFgBReNS7I7ilLf4gjwY25mAp/97Fx+cfFodh+u4ao/r+eml7LZ4oFfqtWNrSzJLmTFtsNkJITxo/MymZgS3ashfKamxvDuPWcSG+bg5hezB9xd91o4vMCq3ccwBhZM0MKhPFeoI4A7zx7Oup+fy0MLRrOzuJornl3PHa9uYPfhGrvjAbClsJJL/riOPUdqmD8uiZtmpxEedGpn7FNiQvnb92cRHRbIba9s4GB5fR+n9VxaOLzABzuPkhYXyqhBA+9cqvI+oY4A7vrOcNb97Fx+etEosvMruPiP67hnyWZyS2ptyeR0Gp77LI9r/vIlxsCdZw/n7JEJ+J3mQKFDokN49dYZOI3h1pc3UN0wMOY60cLh4aoaWvgyr5z54wfraLjKq4QFBXDPuSNY9/N53DdvBJ/sLeHCpz7jgWVbKSxv6LccR6ubuOWVDfzHyr2cNyaRlf9yFqmxfTclQUZCOM/fNJ3CigZ+unzbgBimRQuHh/tw11HanIYF4/U0lfJOUSGB/OTCUXz2s3O546wM3t9+hHlPfMIv3tnBkepGt72vMYZ3txRz4VOfkp1fzm8XjeMvN0wjKrTvb1w8Iy2WBxeM5qPdx3jpi4I+P76n0ctxPdy7Ww6THh/GxJQou6ModVI9uVs9LS6MH58/kk/2lbA0u4hlG4q4dkYqt85JIyMhvM+y5JXW8djKvazec4ypqdE88d3Jbr/z+/a56WTnV/DYyj1MTY1mSmqMW9/PTtri8GCHqxr5Kr+cyycn62kq5TMiQwJZOCmZBy4cyeSh0SzdUMS8Jz7l1pezWbP3GK3tzlM+dkltEw+/s4MLn/qML/PKeGjBaN66+8x+GS5ERPj91ZNIigrm3iVbqGro+u5zX6AtDg+2YtthjIHLpwyxO4pSfS4m1MGVU1P48w3TeCPrIK9/dZDbXtlITGggCyYMZv64JKYOi+n2qqeWNidfHijn3S3FvL/9CE5juGFmKvedl0l8eFA/fRqXqNBAnrluKlf9eT0Pv7OT/75uik/+0aeFw0MZY3hnczFTUqMZFqeDqynflRARxP3nj+QH5wzns31lrNh2mHc2F7MkqxA/gdFJkUxMiSIlJoTIkED8/YSG5naKqxrZX1LL1sIq6lvaCQ8K4NoZQ7l1TjppNg5IOGloNA9cOJLffZDDvM2JXDUtxbYs7qKFw0NtLqwi51gtj105we4oSvWLoAB/Lhg7iAvGDqKhpY0NBZVsOljJpoMVrNp9jPL6b576CXP4k54QxlXTUjgrM4GzMj1nANC7zh7OJzml/NuKXcxIj2VoH17F5Qm0cHioJVmFhDn8uWySnqZSvu1knepJkcFcMmEIl0yA1nYnzW1OnE6DI8CPoAA/rvfQSc38/YQnvzuJBU+v48dLt/LmnbMI8PedLmXf+SQ+pLqhlfe2H2bRlORTvqtVKV8T6O9HeFAAkSGBBAf6e3zfQUpMKL+9fDwbD1byl0/z7I7Tp7RweKC3NhXR3ObkuhmpdkdRSp2Gy6cks3DSEJ5evZ9tPjSelRYOD9PW7uTlLwqYkRbL+GS9d0Mpb/fby8eTGBHE/Uu30tDSZnecPqGFw8Os3HmU4qpGvn92ht1RlFJ9ICokkCe/N5mC8np++94eu+P0CS0cHsQY10BsGfFhnDdaJ2xSylfMyojjrrOH87fsQlbtPmZ3nNOmPa8eZNXuY+wsruF3V03Ez8+zO/6U8gQ9GebEUzxwwUjW7S/l529vZ9LQs0iM8N652rXF4SGcTsOTq/aRFhfKlVOT7Y6jlOpjjgA//rB4MvXNbfxs+XavHkVXC4eHeG/HEfYereXHF4z0qeu9lVL/NCIxgocvGcMnOaW89tVBu+OcMv2G8gD1zW08tnIPYwdHculEveFPKV9246xhnDMqgUff38O+Y/ZMbHW6tHB4gGfW5nKkuonfLBqHv/ZtKOXTRITfXT2RiOBA7nh1IxX13jeKrhYOm+0+XMPz6w5w5ZRkpqfF2h1HKdUPEiOCee6maRyraeKu1zbS3NZud6Re0cJho+a2dh5YtpXoUAe/vHSs3XGUUv1oamoMT3x3EhsKKnnw7R1e1Vmul+Pa6LGVe9l7tJaXbplObJjD7jhKqX526cQh5JfW88SqfQyOCuanF43y+DG4QAuHbZZtLOKV9QXcNiedeaMH2R1HKWWTe+eN4HB1I89+kkegvx/3n5/p8cVDC4cNPt1Xyi/f2cmZw+P4xcWj7Y6jlLKRiPDo5RNobTf84eP9NLS08dCCMR59E7AWjn62PreMu17byIjEcP58/TS9Z0MphZ+f8LurJhLm8Of5dfkcrm7i91dPJNThmV/RnpnKR727pZifLt9GenwYr90+g6jQQLsjKaU8hJ+f8KuF4xgcHcLjH+wlr6SOP107hcxBEXZH+xb9c7cfNLW286/v7uT+pVuZNiyGt+46k7jwILtjKaU8jIhw93eG8/ItZ1BS28ylf/qcv36aR2u70+5o36CFw42MMazafYwLn/qM1746yPfPSufV27SloZQ6uXNGJfLB/WdxVmYCj/3fXuY//Rnvbz+C0+kZl+zqqSo3aGpt56Pdx3hh3QG2H6pmRGI4S+6YyZkj4u2OppTyEokRwbxw83Q+3nOM/1i5h3uWbCYtLpRrpg/lqqkpJEXZN7quWwuHiMwH/gD4Ay8YY/6z0+tBwP8A04By4HvGmALrtYeA24F24F+MMR/25Jh2MMZwqLKRL3LLWLe/jHX7S6lpaiM1NpTHrpzA1dNSCNROcKXUKThvzCDOGZXIe9sPsySrkN9/mMMTH+UwIz2W2RnxzMqIZdLQaIID/fstk9sKh4j4A88AFwCHgA0issIYs7vDZrcDlcaYESKyGHgc+J6IjAUWA+OAIcBqERlp7dPdMftMTVMrDc3t1Le0Ud/cRn1zO7VNrZTWNVNa28zR6ib2l9Sx/1gtNU2uKSGTIoO5aFwSCycPYc7weI++pE4p5R38/YRFk5NZNDmZgrJ6lm86xNqcEp7+eB9mNfgJpMaGMiIxnNTYMBIjg0gIDyIpKpg5bjjT4c4Wxwwg1xhzAEBE3gQWAR2/5BcBv7KWlwP/La47XxYBbxpjmoF8Ecm1jkcPjtlnpv/7alraTtwpFR/uICMhnIWThzByUASzM+IYkRju8TfvKKW8V1p8GP/volH8v4tGUdXQQlZ+BbuKq8krrSe3pI4vcstpbHWNfRUfHsTGX57f5xncWTiSgaIOzw8BM0+0jTGmTUSqgThr/Ved9j0+u1F3xwRARO4E7rSe1olIzil8BoB4oKyrFw4Cm07xoG5wwpweyFuyektO0Kzu8K2c19sUpAe6/Dc9CMi/nvIxh53oBZ/tHDfGPAc8d7rHEZGNxpjpfRDJrbwlJ3hPVm/JCZrVHbwlJ/R/Vnf22BYDQzs8T7HWdbmNiAQAUbg6yU+0b0+OqZRSyo3cWTg2AJkiki4iDlyd3Ss6bbMCuNlavhpYY1xjC68AFotIkIikA5lAdg+PqZRSyo3cdqrK6rO4F/gQ16WzLxljdonIb4CNxpgVwIvAa1bndwWuQoC13TJcnd5twD3GmHaAro7prs9gOe3TXf3EW3KC92T1lpygWd3BW3JCP2cVb5o8RCmllP30rjSllFK9ooVDKaVUr2jhsIjINSKyS0ScIjK902sPiUiuiOSIyEUd1s+31uWKyIP9n9qzcnTI85KIlIjIzg7rYkVklYjst/4bY60XEfmjlX27iEztx5xDRWStiOy2fvY/8sSsIhIsItkiss3K+WtrfbqIZFl5lloXjGBdVLLUWp8lImn9kbNTZn8R2SIi73lyVhEpEJEdIrJVRDZa6zzq52+9d7SILBeRvSKyR0Rm25rTGKMPVz/PGGAU8AkwvcP6scA2IAhIB/Jwdcz7W8sZgMPaZqwNuT0iR6dMZwNTgZ0d1v0OeNBafhB43Fq+GPg/QIBZQFY/5hwMTLWWI4B91s/bo7Ja7xduLQcCWdb7LwMWW+v/AvzAWv4h8BdreTGw1IbfgQeAJcB71nOPzAoUAPGd1nnUz99671eBO6xlBxBtZ85+/WXyhkcXheMh4KEOzz8EZluPD0+0XT/m9YgcXeRK61Q4coDB1vJgIMda/itwbVfb2ZD5H7jGQfPYrEAosBnXiAllQEDn34Pjv6PWcoC1nfRjxhTgY2Ae8J71BeapWbsqHB7188d1f1t+538XO3PqqarudTV0SvJJ1vc3T8nRnUHGmCPW8lFgkLXsEfmtUyRTcP0173FZrVM/W4ESYBWuVmaVMaatiyzfGMoHOD6UT395GvgZcHygtzg8N6sBPhKRTeIapgg87+efDpQCL1un/14QkTA7c/rskCNdEZHVQFIXLz1sjPlHf+cZqIwxRkQ85jpwEQkH3gbuN8bUSIdBKj0lq3HdxzRZRKKBd4DR9ibqmohcCpQYYzaJyDk2x+mJucaYYhFJBFaJyN6OL3rIzz8A16nf+4wxWSLyB1ynpr7W3zkHVOEwxpzKMJEnG+bEE4Y/8ZZhWI6JyGBjzBERGYzrL2ewOb+IBOIqGm8YY/7uyVkBjDFVIrIW1+meaBEJsP5S75jleM5D8s2hfPrDHGChiFwMBAORuObP8cSsGGOKrf+WiMg7uEbh9rSf/yHgkDEmy3q+HFfhsC2nnqrqnqcPf+IpObrTcXiZm3H1Jxxff5N1JcgsoLpD89utxNW0eBHYY4x50lOzikiC1dJAREJw9cPsAdbiGqqnq5xdDeXjdsaYh4wxKcaYNFy/i2uMMdd7YlYRCRORiOPLwIXATjzs52+MOQoUicgoa9V5uEbVsC+nuzt2vOUBXIGrsjcDx/hmh/PDuM4p5wALOqy/GNeVOHm4TnfZld0jcnTI8zfgCNBq/Zvejuu89cfAfmA1EGttK7gm58oDdtDhwoR+yDkX1znu7cBW63Gxp2UFJgJbrJw7gUes9Rm4/ojJBd4Cgqz1wdbzXOv1DJt+D87hn1dVeVxWK9M267Hr+P87nvbzt957MrDR+h14F4ixM6cOOaKUUqpX9FSVUkqpXtHCoZRSqle0cCillOoVLRxKKaV6RQuHUkqpXtHCoZRSqle0cCillOqV/w9R9JcyVIKABAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "token_lens = []\n",
    "for txt in tqdm(df.text):\n",
    "  tokens = tokenizer.encode(txt, max_length=512)\n",
    "  token_lens.append(len(tokens))\n",
    "\n",
    "sns.distplot(token_lens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iksKn0SoHX42"
   },
   "source": [
    "As we can see the largest length of sentence is about 520 but that length is going out of memory so we will user smaller max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zGNKZTzzUTjA"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 120\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self,text,targets,tokenizer,max_len):\n",
    "        self.text = text\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        text = str(self.text[item])\n",
    "        target = self.targets[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            )\n",
    "        \n",
    "        return {\n",
    "            'review_text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.long)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val=pd.read_csv('Yelptrain.csv',nrows=100)\n",
    "df_val[\"label\"].replace({1: 0, 2: 1}, inplace=True)\n",
    "df_test=pd.read_csv('Yelptest.csv',nrows=400)\n",
    "df_test[\"label\"].replace({1: 0, 2: 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K91eCrRFHlZ9"
   },
   "source": [
    "#### Creating Pytorch dataset by converting the text into numerical vectors using the tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2YxXYIaPVtFP",
    "outputId": "3ccf6e35-5fdf-41bb-92f3-7746c5234525"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 2), (100, 2), (400, 2))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efH_dky2gtkv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/silaruddin/ENTER/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass classes=[0 1], y=[0 1 0 0 1 0 0 0 1 1 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 0 0 0 1\n",
      " 1 1 0 0 0 0 0 1 0 1 1 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0\n",
      " 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 0\n",
      " 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 1 1 1 1 0 0 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1\n",
      " 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 1 1 1 1\n",
      " 1 1 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0 1 0 0 1\n",
      " 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0\n",
      " 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 0 0 1 0\n",
      " 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0 0 0 1 0\n",
      " 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1\n",
      " 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1\n",
      " 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0\n",
      " 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 1 1\n",
      " 1 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1\n",
      " 1 1 1 1 1 0 1 0 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(df_train.label.values),\n",
    "                                                 df_train.label.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SAQtQgVjVwLu"
   },
   "outputs": [],
   "source": [
    "def create_data_loader(df,tokenizer,max_len,batch_size):\n",
    "    ds = ReviewDataset(\n",
    "        text = df.text.to_numpy(), \n",
    "        targets = df.label.to_numpy(),\n",
    "        tokenizer = tokenizer,\n",
    "        max_len=max_len)\n",
    "\n",
    "    return DataLoader(ds,\n",
    "                      batch_size=batch_size,\n",
    "                      num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QoLrF3sMHva6"
   },
   "source": [
    "#### Creating Pytorch dataset loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kKVY9zoOWn-_"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qd3Ut0vvWrnl"
   },
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uo9gBhJWZD5g"
   },
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "    super(SentimentClassifier, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "    self.drop = nn.Dropout(p=0.4)\n",
    "    #self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "    self.out1 = nn.Linear(self.bert.config.hidden_size, 128)\n",
    "    self.drop1 = nn.Dropout(p=0.4)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.out = nn.Linear(128, n_classes)\n",
    "  \n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    _, pooled_output = self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "    #output = self.relu(pooled_output)\n",
    "    output = self.drop(pooled_output)\n",
    "    output = self.out1(output)\n",
    "    output = self.relu(output)\n",
    "    output = self.drop1(output)\n",
    "    return self.out(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0KbiOWa_H1AJ"
   },
   "source": [
    "#### Creating a fine-tuned bert model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p7AN7dDgaJ5U"
   },
   "outputs": [],
   "source": [
    "model = SentimentClassifier(len(class_name))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sOIjTtHXaS47"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "#class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "#weight=class_weights\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ltvyv4zHH5jW"
   },
   "source": [
    "#### Initializing optimizer and loss function for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UesSFC04a6Ec"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model,data_loader,loss_fn,optimizer,device,scheduler,n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for data in data_loader:\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "        targets = data['targets'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "            )\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs,targets)\n",
    "\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2r839zb7IAGM"
   },
   "source": [
    "#### Function to train our model on each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uGMeAOPecEYx"
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "  model = model.eval()\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "      loss = loss_fn(outputs, targets)\n",
    "      correct_predictions += torch.sum(preds == targets)\n",
    "      losses.append(loss.item())\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbT8v63yILcB"
   },
   "source": [
    "#### Function to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "yKgu39sXcVbh",
    "outputId": "e6b1040c-dc0f-4641-b414-d4c75a3d2f54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(df_train)\n",
    "    )\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_data_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(df_val)\n",
    "    )\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "        best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "PV9URv_lci66",
    "outputId": "8fa5dfdc-9727-4440-cd8b-b00988a7fd53"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history['train_acc'], label='train accuracy')\n",
    "plt.plot(history['val_acc'], label='validation accuracy')\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I4yaZ7VnhsjQ",
    "outputId": "bf2f32b0-e494-49d9-d122-2313c7f6e820"
   },
   "outputs": [],
   "source": [
    "test_acc, _ = eval_model(\n",
    "  model,\n",
    "  test_data_loader,\n",
    "  loss_fn,\n",
    "  device,\n",
    "  len(df_test)\n",
    ")\n",
    "test_acc.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FDe7XzAk0OUL"
   },
   "outputs": [],
   "source": [
    "#### Model Testing\n",
    "def get_predictions(model, data_loader):\n",
    "  model = model.eval()\n",
    "  review_texts = []\n",
    "  predictions = []\n",
    "  prediction_probs = []\n",
    "  real_values = []\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      texts = d[\"review_text\"]\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "      review_texts.extend(texts)\n",
    "      predictions.extend(preds)\n",
    "      prediction_probs.extend(outputs)\n",
    "      real_values.extend(targets)\n",
    "  predictions = torch.stack(predictions).cpu()\n",
    "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "  real_values = torch.stack(real_values).cpu()\n",
    "  return review_texts, predictions, prediction_probs, real_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "betgAymS0ORr"
   },
   "outputs": [],
   "source": [
    "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
    "  model,\n",
    "  test_data_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "mIaYIs8jbIx9",
    "outputId": "f455f25a-88bd-43b7-f229-61e8c1db93ce"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test, y_pred, target_names=class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "TubE-RH4bIlG",
    "outputId": "20208ce3-2d38-439e-c2af-7119b722059a"
   },
   "outputs": [],
   "source": [
    "def show_confusion_matrix(confusion_matrix):\n",
    "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
    "  plt.ylabel('True sentiment')\n",
    "  plt.xlabel('Predicted sentiment');\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(cm, index=class_name, columns=class_name)\n",
    "show_confusion_matrix(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gXgNzPnI0OPR"
   },
   "outputs": [],
   "source": [
    "review_text = \"the food was delicious but it was spicy\"\n",
    "encoded_review = tokenizer.encode_plus(\n",
    "  review_text,\n",
    "  max_length=MAX_LEN,\n",
    "  add_special_tokens=True,\n",
    "  return_token_type_ids=False,\n",
    "  pad_to_max_length=True,\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "dOAS8pZt0OKR",
    "outputId": "9f8ccd5c-b49d-4a92-86d6-363c9d8bd252"
   },
   "outputs": [],
   "source": [
    "input_ids = encoded_review['input_ids'].to(device)\n",
    "attention_mask = encoded_review['attention_mask'].to(device)\n",
    "output = model(input_ids, attention_mask)\n",
    "_, prediction = torch.max(output, dim=1)\n",
    "print(f'Review text: {review_text}')\n",
    "print(f'Sentiment  : {class_name[prediction]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XqA5h2OnJeds"
   },
   "source": [
    "Model is working preety well "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Sentiment-Classification-Using-Transformers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
